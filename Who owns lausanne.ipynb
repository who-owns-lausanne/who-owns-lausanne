{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who owns Lausanne? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "In order to run this notebook you will need multiple dependecies. We assume you have a running `conda` distribution.\n",
    "\n",
    " - `numpy` needs to be in version `>=0.15`\n",
    " - The JSON processing tool `jq` is needed. Install with your OS' package manager (e.g. `brew install jq`).\n",
    " - `pip install yq geopy shapely geopandas`\n",
    " - If you want to have a look at the raw geographical data you have to intall [QGIS](https://www.qgis.org/en/site/), an open source geo information system tool.\n",
    "\n",
    "_If you are running an older version of macOS (e.g. 10.11) you might need to call `ulimit -n 1024` in the terminal before starting `jupyter`. This can avoid a bug with one of the preprocessing scripts._\n",
    "\n",
    "## Imports\n",
    "\n",
    "We start importing some core python libraries that will be used throughout the whole Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font=\"Helvetica Neue\")\n",
    "themecolors = sns.color_palette([\"#5B698C\",\"#84CFAC\", \"#BD8273\",\"#0E285C\",  \"#B2A7DB\"])\n",
    "sns.set_palette(themecolors)\n",
    "\n",
    "sns.set_style(\"whitegrid\", {\n",
    "    \"axes.edgecolor\": \"0.9\",\n",
    "    \"grid.color\": \"0.9\"\n",
    "})\n",
    "\n",
    "# Auto reload module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Suppress future warning (generated by seaborn)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Public data and owners\n",
    "\n",
    "We obtained ftp access from the Lausanne office of cadastre. The data is a collection of ESRI shapefiles, describing roads, buildings, parcels, trees, waterbodies, and others.\n",
    "Each shapefile is a collection of features, and each feature has an associated geometry (e.g. the shape of a land parcel) and associated attributes ( e.g. the commune responsible for the parcel, the parcel number).\n",
    "\n",
    "We can explore this dataset by using GIS software that supports shapefiles. We used QGIS to explore the dataset.\n",
    "We hoped to find an attribute describing the parcel owner in the parcel shapefile layer, but it wasn't there.\n",
    "We had to resort to web scraping to recover this attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Scraping owners\n",
    "\n",
    "### 1.1.2 Download XML files\n",
    "We wanted to associate each parcel in Lausanne to an owner. To do this, we divided Lausanne's surface in rectangles, and requested parcel informations for these rectangles to a service exposing the owners name.\n",
    "The code for the scraping is in [`/scraping/owners/scrape_owners_to_xml.py`](/edit/scraping/owners/scrape_owners_to_xml.py).\n",
    "\n",
    "The result of owner scraping is a set of 400 xml files, each containing parcel information for a geographical rectangle. The data are saved in the following directory: `data/raw/owners/`.\n",
    "\n",
    "For privacy reason we decided not to push any data on the online github respository.\n",
    "\n",
    "We start exploring the raw owner xml data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"data/raw/owners/\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file is named after the coordinates, in the Swiss systems, of the top-left and bottom-right points bounding the scraped rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"data/raw/owners/\" 2>/dev/null | head -3 # suppress error message by redirecting errors to null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10 \"data/raw/owners/534810.4210526316_155847.0_535161.3710526315_155589.0.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 From XML to a single JSON\n",
    "We use `yq`, `xq` and `jq` programs to extract only the features we care about from the different XML files and save them as a list of objects in a single json file.\n",
    "[`scraping/owners/multiple_xml_to_single_json.sh`](/edit/scraping/owners/multiple_xml_to_single_json.sh) is a small script leveraging the expressiveness of `jq` to efficiently concatenate the XML files into a single json, while also discarding all the attributes we have no interest in.\n",
    "\n",
    "The result file of the shell program is a JSON file`/data/owners/all_owners_dirty.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all XML into one JSON file\n",
    "!scraping/owners/multiple_xml_to_single_json.sh all_owners_dirty.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see errors of the form\n",
    "```\n",
    "jq: error (at <stdin>:1): Cannot iterate over null (null)\n",
    "```\n",
    "you don't have to worry. These are just errors, when `jq` encounters the end of a file. The script is still working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Remove duplicated and  clean owners JSON\n",
    "The generated `all_owners_dirty.json` JSON has duplicate entries, entries concerning other communes than Lausanne and entries with missing owners. Furthermore, JSON is not the best format to handle tabular data. The code in [`scraping/owners/owner_json_to_clean_csv.py`](/edit/scraping/owners/owner_json_to_clean_csv.py) cleans the duplicates and tranfsorms the data into `all_owners.csv` CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dirty data and write it to 'all_owners.csv' \n",
    "import scraping.owners\n",
    "scraping.owners.owner_json_to_clean_csv.main(\n",
    "    './data/owners/all_owners_dirty.json',\n",
    "    './data/owners/all_owners.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of semplicity, we can now remove the legacy file `all_owners_dirty.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ./data/owners/all_owners_dirty.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Joining the owners data with the cadastre shapefiles\n",
    "The result of the previous preprocessing steps is a CSV file with three columns: commune number, parcel number, and the owner name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_owners = pd.read_csv('data/owners/all_owners.csv')\n",
    "all_owners.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cadastral data - data exploration\n",
    "\n",
    "We would like to add the owner name to the attributes of the parcels shapefile that we obtained from \"Office du Cadastre\". To do so, we import the `all_owners.csv` csv and the shapefile in *QGIS*, and we join this two \"tables\" by parcel number. The resulting geographical layer contains all the geographical features representing the parcels, and additionally the owner name for each parcel. \n",
    "\n",
    "We can now export this layer as a GeoJSON, making sure to use `WGS-84` as the coordinate system, and continue our exploration.\n",
    "\n",
    "The exported *geojson* file is saved at `data/owners/all_owners_parcelles.geojson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "all_owners_parcelles_pd = geopandas.read_file('./data/owners/all_owners_parcelles.geojson')\n",
    "\n",
    "# Drop not used columns and rename columns\n",
    "all_owners_parcelles_pd.drop(['ID_GO', 'TYPE', 'EGRID', 'GID_OLD', 'NUMCOM'], axis='columns', inplace=True)\n",
    "all_owners_parcelles_pd.rename({'NO_PARC': 'parc_num', 'proprio': 'owner', 'NOM_COM':'commune'}, \n",
    "                               axis='columns', inplace=True)\n",
    "\n",
    "all_owners_parcelles_pd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represent a parcell and each parcel has a unique owner and a *polygon* object (geometry) that represent the surface area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_owners_parcelles_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Who is the biggest real estate owners?\n",
    "\n",
    "We can now quickly answer questions such as who are the 30 biggest property owners in Lausanne, by using the number of parcels owned as a measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_per_owner = all_owners_parcelles_pd['owner'].value_counts()\n",
    "parcels_per_owner.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the biggest owners are either corporations, pension funds, or public institutions. \n",
    "\n",
    "We note that there is no a single private person in the list. This data tell us that our analysis will have to take into consideration other kind of owners than the private ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_owners_parcelles_pd['owner'] == 'Commune de Lausanne') / len (all_owners_parcelles_pd) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also records that the Lausanne municipality owns ~12% of properties in Lausanne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Unique owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the non assigned values, we can see both the total number of parcels owned and the unique owners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners = all_owners_parcelles_pd['owner'].dropna()\n",
    "print('Total parcels', len(owners))\n",
    "print('Unique owners', len(owners.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are almost 8'000 parcels in Lausanne. \n",
    "\n",
    "We are interestd to know how many people and societies own them. This number doesn't account for PPE (_propriété par étage_, single flats owned by privates). A lower bound on the owners can be estimated by discarding the PPE entries altogether:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds_owners = len(owners[~owners.str.contains('PPE ')].unique())\n",
    "print('Unique lower-bounds owners', lower_bounds_owners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lower bound for the number of owners. Although, the real number is likely to be much higher since it's unprobable that most of these unique owners are also owners of a PPE share."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Visualizing the distribution of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute portion of missing values\n",
    "all_owners_parcelles_pd['owner'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22% of the parcels don't have owner information. Indeed, many parcels reperesent roads, and as such they didn't have an owner on the site we scraped. Also we didn't scrape the values for the northern part of Lausanne, which is mostly farmland and woods.\n",
    "\n",
    "Let's try to visualize the missing values on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "!mkdir export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import missing_values\n",
    "m = missing_values(all_owners_parcelles_pd._to_geo())\n",
    "m.save('export/missing_values.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/missing_values.html)\n",
    "\n",
    "This visualization is not very snappy or legible, but we can interpret it as follows:\n",
    "\n",
    "- Red areas are parcels for which the proprietary is not assigned, i.e `None`. The northern parts of Lausanne were not scraped, since we didn't want to overload the scraped website and since they're mostly rural areas. It is expected that they are red.\n",
    "- Zooming into central Lausanne, we see that roads have unknown owners. This is also expected.\n",
    "- For some areas blue and red overlap, yielding purple parcels. This is because the dataset is slightly dirty and some bigger parcels with no owners _contains_ smaller parcels with known owners. Therefore the colors overlap.\n",
    "\n",
    "Having asserted that the dataset is fairly sane, we can drop the features were the owner is `np.nan`, since they will be of no use to us (roads), and will make the map drawing slower.\n",
    "\n",
    "How many parcelles have no owner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_owners_parcelles_pd['owner'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select only the parcelles for which there is a owner, i.e drop not assigned rows to our dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_owners_parcelles_pd = all_owners_parcelles_pd.dropna().copy()\n",
    "len(complete_owners_parcelles_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, our analysis will be based on such dataframe: `complete_owners_parcelles_pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_owners_parcelles_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2.4 Show parcels by owner type\n",
    "\n",
    "The parcel owner format allows us to know the category of each owner. \n",
    "We will use similar categories as the statistical office of the city of Lausanne [here](https://www.lausanne.ch/officiel/statistique/quartiers/tableaux-donnees.html):\n",
    "\n",
    "- privates\n",
    "- public institutions\n",
    "- companies (corporations)\n",
    "- cooperatives\n",
    "- pension funds\n",
    "- foundations\n",
    "- PPE\n",
    "\n",
    "Societies are detected by having 'AG' or 'SA' in their name. Similary for cooperatives, foundations, and pension funds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def categorize(owner):\n",
    "    \"\"\"Given a owner string, return category of such owner\"\"\"\n",
    "    regex_cats = [\n",
    "            ('retraites|pension|prévoyance|prevoyance|BVK|'+\\\n",
    "             'anlagestiftung|fondation d\\'investissement|fondation de placement|'+\\\n",
    "             'vorsorge|anlage stiftung', 'pension'),\n",
    "            ('commune de lausanne|dfire|cff|domaine public|Etat de Vaud|Service du logement', 'public'),\n",
    "            (r's\\.a\\.|\\bsa\\b|\\bag\\b|société anonyme|sàrl|\\bBCV\\b|SICAV', 'société'), # BCV société ou public?\n",
    "            (r'fondation|\\bstiftung|foundation|association|fédération', 'fondation/association'),\n",
    "            (r'\\bppe\\b|copropriété|copropriete|parcelles', 'PPE'),\n",
    "            ('société coopérative|societe cooperative', 'coop'),\n",
    "            ('.*', 'private')\n",
    "    ]\n",
    "    for cat_re, category in regex_cats: \n",
    "        if re.search(cat_re, owner, flags=re.IGNORECASE):\n",
    "            return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_owners_parcelles_pd['owner_type'] = complete_owners_parcelles_pd['owner'].apply(lambda r:\n",
    "                                                                                        categorize(r))\n",
    "complete_owners_parcelles_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visually see with a map the distribution of owners by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import by_owners_category\n",
    "parcels_categories = complete_owners_parcelles_pd[['parc_num', 'owner_type']]\n",
    "parcels_categories = parcels_categories.set_index('parc_num')\n",
    "m = by_owners_category(complete_owners_parcelles_pd._to_geo(), parcels_categories )\n",
    "m.save(\"export/by_owners_category.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/by_owners_category.html), the different owners catagories are:\n",
    "\n",
    "<p> <strong style='color:#b3de69'>public institutions: </strong><em>the city, the swiss railways etc.</em></p>\n",
    "\n",
    "<p><strong style='color:#bebada'>pension or similar funds: </strong><em>investment foundations,the city’s\n",
    "pension fund, etc.</em></p>\n",
    "\n",
    "<p><strong style='color:#fb8072'>corporations: </strong><em>listed public companies like Swiss Life S.A., Régie\n",
    "  Chamot &amp; Cie S.A. etc.</em></p>\n",
    "\n",
    "<p><strong style='color:#ffe300'>cooperatives: </strong><em>registered cooperative companies like Migros, la\n",
    "  Mobilière etc.</em></p>\n",
    "\n",
    "<p><strong style='color:#80b1d3'>foundations and associations: </strong><em>for example the olympic foundation for\n",
    " cultural heritage.</em></p>\n",
    "\n",
    "<p><strong style='color:#fdb462'>PPE: </strong><em>the single flats in a building are owned by different people\n",
    " – in french</em> proriété par étage.</p>\n",
    "\n",
    "<p><strong style='color:#8dd3c7'>individual privates: </strong><em>the whole building is owned by a private\n",
    " citizen.</em></p>\n",
    "\n",
    "## 2. Rents data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scraping\n",
    "\n",
    "In order to analyse how ownership patterns influence prices, we needed to complement the owners dataset with rent prices.\n",
    "Rent prices are generally not public, but we can scrape from real estate websites' current rent listings, and extract the prices from there.\n",
    "\n",
    "We scraped from [anibis.ch](https://www.anibis.ch/fr/default.aspx), [homegate.ch](https://www.homegate.ch/fr) and [tutti.ch](https://tutti.ch) and extracted up-to-date real estate announcements.\n",
    "\n",
    "#### 2.1.1 Download the raw rents data\n",
    "\n",
    "The scripts to download the data from the three portals are the following:\n",
    "\n",
    "- for homegate: [`scraping/homegate/scrape_homegate.py`](/edit/scraping/homegate/scrape_homegate.py)\n",
    "\n",
    "- for anibis:\n",
    "    1. [`scraping/anibis/anibis_scrape_listings.py`](/edit/scraping/anibis/anibis_scrape_listings.py) to download the index of results matching rents in lausanne\n",
    "    2. [`scraping/anibis/anibis_scrape_offers.py`](/edit/scraping/anibis/anibis_scrape_offers.py) to download each single rent offer, given a parsed index\n",
    "\n",
    "- for tutti:\n",
    "    1. [`scraping/tutti/tutti_scrape_listings.py`](/edit/scraping/tutti/tutti_scrape_listings.py) to download the index of results matching rents in lausanne\n",
    "    \n",
    " \n",
    "The raw rents data are then saved in `data/raw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Parse the rents data\n",
    "\n",
    "\n",
    "Once downloaded, we parse the data in an agreed JSON format.\n",
    "\n",
    "#### Tutti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.tutti import tutti_parse_listings\n",
    "tutti_parse_listings.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anibis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`scraping/anibis/anibis_parse_listings.py`](/edit/scraping/anibis/anibis_parse_listings.py) to parse the listings index.\n",
    "2. [`scraping/anibis/anibis_parse_offers.py`](/edit/scraping/anibis/anibis_parse_offers.py) to parse the pages for each offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Removing duplicates\n",
    "\n",
    "Most rent listings are published in several websites. When merging the data sources, we first need to figure out which results are present in multiple datasets to avoid duplicate datapoints. We consider listings to be duplicates if they have the same address and the same price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jq length data/raw/rents/tutti.json\n",
    "!jq length data/raw/rents/anibis_with_streets.json\n",
    "!jq length data/raw/rents/homegate.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before cleaning and merging we have a total of ~1300 offers.\n",
    "\n",
    "The parsed files have this structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tutti = pd.read_json(\"./data/raw/rents/tutti.json\")\n",
    "pd_tutti.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to removing duplicates, [`cleaning/merge_rent_offers.py`](/edit/cleaning/merge_rent_offers.py) clean offers without prices, without addresses, or without surface area. \n",
    "\n",
    "The merge script return a JSON file with all listings, one each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaning as cleaning\n",
    "filenames = [\"./data/raw/rents/tutti.json\", \n",
    "             \"./data/raw/rents/anibis_with_streets.json\",\n",
    "            \"./data/raw/rents/homegate.json\"]\n",
    "dirty_rent_prices = cleaning.merge_rent_offers.main(filenames)\n",
    "len(dirty_rent_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mapping street addresses to coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_rent_prices_pd = pd.DataFrame.from_dict(dirty_rent_prices)\n",
    "dirty_rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above we can see that the address is in a textual form. \n",
    "\n",
    "Also, it is clear that there will be more cleaning needed. The first address is a phone number instead of an actual address. This sanitisation is automatically provided by the next script.\n",
    "\n",
    "To perform geographical queries on addresses, we need to convert them to coordinates. To do so, we use the cadastral layer of building addresses, provided by the Cadastral office of Lausanne.\n",
    "During merging of the three datasets, the addresses were standardized to use the format used by this cadastral layer.\n",
    "\n",
    "To map an address to a coordinates couple, we iterate over all buildings in Lausanne, and check if the street name and the street number match those of our address. If there's a match, we extract the coordinates of the building from the cadastral layer. If there isn't we drop the offer (like the phone number above) and therefore perform some cleaning.\n",
    "\n",
    "We use [`cleaning/address_to_coords.py`](/edit/cleaning/address_to_coords.py) to execute the operations descripted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices = cleaning.address_to_coords.main(dirty_rent_prices)\n",
    "rent_prices_pd = pd.DataFrame.from_dict(rent_prices)\n",
    "# dropn not used columns\n",
    "rent_prices_pd.drop(['city', 'meuble'], axis='columns', inplace=True)\n",
    "\n",
    "# Explode from 'position' column latitude and longitude\n",
    "long_lat = rent_prices_pd['position'].apply(lambda pos: pd.Series(pos))\n",
    "long_lat.columns = ['long', 'lat']\n",
    "long_lat.head(2)\n",
    "rent_prices_pd =  pd.concat([rent_prices_pd, long_lat], axis='columns')\n",
    "\n",
    "# Convert surface type to float\n",
    "rent_prices_pd['surface'] = rent_prices_pd['surface'].astype(float)\n",
    "rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rent_prices_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting *Pandas* DataFrame `rent_prices_pd` if finnaly cleaned. We can now start visualizing and intrpret the dataset.\n",
    "\n",
    "We also notice that during the cleaning phase we went from than 1300 rents announcements to 469. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the rents dataset\n",
    "\n",
    "#### 2.4.1 Rent position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better spatial understanding, we will increment on some of the maps the quartiers of Lausanne. We start loading the quartiers on a *geopandas* DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartiers_pd = geopandas.read_file('data/raw/maps/quartiers.geojson')\n",
    "quartiers_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import marker_rents_with_quartiers\n",
    "m = marker_rents_with_quartiers(rent_prices_pd, quartiers_pd._to_geo() )\n",
    "m.save(\"export/marker_rents_with_quartiers.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/marker_rents_with_quartiers.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Rent position by quartier\n",
    "\n",
    "We want to map each offer to a quartier. Each rent data-point has a pair of coordinates localizing it in space. We use the python library `shapely`, that allows us to perform geometrical queries, to find the _quartier_ for each rent offer.\n",
    "\n",
    "We start defining a function `get_quartier()` that takes as input longitudine and latitude of the queried place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the two data structures needed\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "quartiers = quartiers_pd._to_geo()\n",
    "def get_quartier(lat, long):\n",
    "    for quartier in quartiers['features']:\n",
    "        # skip because we don't have owner data for forest areas\n",
    "        if quartier['properties']['Name'] == '90 - Zones foraines':  \n",
    "            return None\n",
    "\n",
    "        \"\"\"Given longitute and latitude, return quartier in Lausanne\"\"\"\n",
    "        pos = Point(long, lat)\n",
    "        quartier_vertices = [(east, north) for east, north, z in quartier['geometry']['coordinates'][0]]\n",
    "        quartier_poly = Polygon(quartier_vertices)\n",
    "        if quartier_poly.contains(pos):\n",
    "            return quartier['properties']['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate over all rents and found the respective quartier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices_pd['quartier'] = \\\n",
    "    rent_prices_pd[['lat', 'long']] \\\n",
    "    .apply(lambda row: get_quartier(row['lat'], row['long']), axis='columns')\n",
    "rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check by changing the color of the marker depending on the found _quartier_ and displaying all of it on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import circles_rents\n",
    "m = circles_rents(rent_prices_pd, quartiers_pd._to_geo() )\n",
    "m.save(\"export/circle_rents.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/circle_rents.html)\n",
    "\n",
    "#### 2.4.3 Rent prices by CHF/M^2\n",
    "\n",
    "We are interested in the prices of rents by surface area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices_pd['CHF/m2'] = rent_prices_pd[['price', 'surface']].apply(lambda row:\n",
    "                                                                      float(row['price'])/float(row['surface']), \n",
    "                                                                      axis='columns')\n",
    "rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import circles_prices\n",
    "m = circles_prices(rent_prices_pd)\n",
    "m.save('export/circle_prices.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/circle_prices.html)\n",
    "\n",
    "We can already see that in general real estates close to the center and/or close to the lake are more expensive.\n",
    "\n",
    "We can now see the median price by quartiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display median price per neighborhood\n",
    "rent_prices_pd[['CHF/m2', 'quartier']].groupby('quartier').agg('median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As aleardy noticed on the maps, the center is the expensive quartier of Lausanne. Later we will come back to that facts and enhance our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Map each offer to an owner\n",
    "\n",
    "What about merging the two dataset that we have (`rent_prices_pd` and `complete_owners_parcelles_pd`) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_owners_parcelles_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each parcel has an owner and a geometry, which is a `MultiPolygon`. A `MultiPolygon` is a list of `Polygon`s. Every `Polygon` is a list of \"linear rings\". The first linear ring defines the outer perimeter of the polygon, and the next linear rings define holes in the polygon.\n",
    "For all parcels the multipolygons are made of only 1 polygon, and every polygon only has the outer perimeter and no holes. We can use shapely polygons again to find wether an offer is within a polygon.\n",
    "\n",
    "We define, _get_owner_ that given a position, it return the name of the propretary of such parcelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_owner(pos):\n",
    "    \"\"\"Reutn owner name given longitude and latitude coordinates\"\"\"\n",
    "    pos = Point(pos)\n",
    "    parcelle = complete_owners_parcelles_pd[complete_owners_parcelles_pd['geometry'].contains(pos)]\n",
    "    owner = np.nan\n",
    "    if parcelle['owner'].values.size > 0:\n",
    "        owner = parcelle['owner'].values[0]\n",
    "    return owner\n",
    "get_owner(rent_prices_pd['position'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore iterate over all *rent prices* and for each values find the respective owner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices_pd['owner'] = rent_prices_pd['position'].apply(lambda pos: get_owner(pos))\n",
    "rent_prices_pd.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpretation of data\n",
    "\n",
    "After a first hand-on on the data, it's time to use some models to answer some open questions. \n",
    "\n",
    "### 3.1 Linear model describing relation of ownership and price\n",
    "\n",
    "As our main goal is to understand the rent price composition, we will perform linear regression on the rent prices. More precisely, we will try to predict the prices of rents in each quartier based on the features:\n",
    "\n",
    " - ownership proportion of each ownership type: ($f_{public}, f_{s.a.}, $...)\n",
    " - distance from the centre of the city: $dist$\n",
    " - the mean price of rents in the _quartier_ $q$ (dependent variable): $price(q)$ \n",
    " \n",
    "The linear model is then:\n",
    "\n",
    "$$\n",
    "price(q) = \\beta_1 f_{public}(q) + \\beta_2  f_{s.a.}(q) + ~...~ + \\beta_j  f_{privates}(q)+  \\beta_k dist(q)\n",
    "$$\n",
    "\n",
    "We will apply linear regression to this model and extract the knowledge from the parameters $\\beta$. One problem could however be, that the ownership pattern itself depends on the distance or vice-versa. In that case we'll be able to check this assumption by predicting the distance from the ownership types:\n",
    "\n",
    "$$\n",
    "dist(q) = \\beta_1 f_{public}(q) + \\beta_2  f_{s.a.}(q) + ~...~ +\\beta_j  f_{privates}(q)\n",
    "$$\n",
    "\n",
    "\n",
    "Now, each rents have it's own owner. We can iterate and add a columns _owner_type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not assigned owner\n",
    "rent_prices_with_owners_pd = rent_prices_pd[~rent_prices_pd['owner'].isna()].copy()\n",
    "\n",
    "rent_prices_with_owners_pd['owner_type'] = rent_prices_with_owners_pd['owner'].apply(lambda r: categorize(r))\n",
    "rent_prices_with_owners_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import scipy\n",
    "\n",
    "covariates = rent_prices_with_owners_pd[['owner_type','CHF/m2']].copy()\n",
    "covariates[\"owner_type\"] = covariates[\"owner_type\"].astype(\"category\")\n",
    "samples_per_cat = covariates[\"owner_type\"].value_counts()\n",
    "\n",
    "covariates = pd.get_dummies(covariates)\n",
    "\n",
    "# drop one indicator to avoid multiple colinearity\n",
    "covariates = covariates.drop(\"owner_type_private\", axis=\"columns\")\n",
    "\n",
    "coeffs = np.empty(covariates.shape)\n",
    "\n",
    "# columns: num of covariates minus the response (y) plus 1 for the intercept\n",
    "\n",
    "# bootstrap confidence interval for linear regression coefficients\n",
    "for i in range(covariates.shape[0]):\n",
    "    sample = covariates.values[\n",
    "        np.random.choice(\n",
    "            covariates.shape[0], size=covariates.shape[0], replace=True\n",
    "        )\n",
    "    ]\n",
    "    lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "    X = sample[:, 1:]\n",
    "    y = sample[:, 0]\n",
    "    lm.fit(X, y)\n",
    "    coeffs[i, 0] = lm.intercept_\n",
    "    coeffs[i, 1:] = lm.coef_\n",
    "\n",
    "alpha = 0.05\n",
    "lower, upper = np.percentile(coeffs, q=((alpha/2)*100, (1 - alpha/2)*100), axis=0)\n",
    "\n",
    "print(\"%-40s\\t%s\\t%s\\t%s\" % (\"feature\", \"%.3f qtile\" % (alpha/2), \"%.3f qtile\" % (1 - alpha/2), \"n\"))\n",
    "print()\n",
    "print(\"%-40s:\\t%f\\t%f\\t%d\" % (\"intercept (average for private owner)\",\n",
    "                              lower[0], upper[0],samples_per_cat['private']))\n",
    "\n",
    "for typ, lower_q, upper_q in zip(covariates.columns[1:], lower[1:], upper[1:]):\n",
    "    print(\n",
    "        \"%-40s:\\t%f\\t%f\\t%d\"\n",
    "        % (typ, lower_q, upper_q, samples_per_cat[typ.split(\"_\")[-1]])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows the confidence interval for each parameter of the linear model.\n",
    "The `intercept` value represents the average price of the 'private' owner category, and the `owner_type_*` rows show the confidence intervals for the weights corresponding to the presence of any of the categorical variables relating to the owner type.\n",
    "Every the confidence intervals for the weights corresponding to every categories contain the value $0$. This leads us to be unable to statistically say that the type of owner influences the price of the apartment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Linear regression on distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask now if there is another relationship that influence rent prices: distance. We try to see the relation price/distance from the port of [_Ouchy_](https://map.geo.admin.ch/?lang=en&topic=ech&bgLayer=ch.swisstopo.pixelkarte-farbe&layers=ch.swisstopo.zeitreihen,ch.bfs.gebaeude_wohnungs_register,ch.bav.haltestellen-oev,ch.swisstopo.swisstlm3d-wanderwege&layers_visibility=false,false,false,false&layers_timestamp=18641231,,,&E=2537733&N=1150883&zoom=7.498594761554026&crosshair=marker).\n",
    "\n",
    "In order to calculate distances with WGS-84 coordinates we use `geopy.great_circle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import great_circle\n",
    "\n",
    "ouchy = 46.50766, 6.62758\n",
    "\n",
    "rent_distances = rent_prices_pd[[\n",
    "    'CHF/m2', \n",
    "    'lat',\n",
    "    'long', \n",
    "    'surface',\n",
    "    'quartier'\n",
    "]].copy().dropna()\n",
    "\n",
    "distances = rent_distances.apply(\n",
    "    lambda row: great_circle((row.lat, row.long), ouchy).km, axis=1\n",
    ")\n",
    "\n",
    "rent_distances[\"distance\"] = distances # distance fom Ouchy port\n",
    "rent_distances.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"distance\", y=\"CHF/m2\", data=rent_distances);\n",
    "plt.title(\"Distance from the station vs. rent prices\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like something, but we need to check the significance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_model = scipy.stats.linregress(\n",
    "    rent_distances.distance, rent_distances[\"CHF/m2\"]\n",
    ")\n",
    "\n",
    "def print_model(model):\n",
    "    for stat in [\"intercept\", \"slope\", \"stderr\", \"pvalue\"]:\n",
    "        print(stat, \": \", getattr(model, stat))\n",
    "\n",
    "print_model(distance_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p-value* for the model is small enough to reject the null hypothesis of no relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_model = scipy.stats.linregress(\n",
    "    rent_distances.lat ** 2, rent_distances[\"CHF/m2\"]\n",
    ")\n",
    "long_model = scipy.stats.linregress(\n",
    "    rent_distances.long ** 2, rent_distances[\"CHF/m2\"]\n",
    ")\n",
    "\n",
    "print_model(lat_model)\n",
    "print()\n",
    "print_model(long_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second analysis shows that it is really the distance to the lake. The latitude model (the higher the latitude the further away from the lake) yields a significant answer of a negative slope.\n",
    "\n",
    "The same is not true for the longitudal model.\n",
    "\n",
    "We check now a possible second influence, namely the surface of a flat on its price per square meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(\n",
    "    scipy.stats.linregress(\n",
    "        rent_distances.surface, rent_distances[\"CHF/m2\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is maybe unexpected but the p-value is the lowest that we encoutered in the entire analysis. It seems like rent prices don't exactly grow linearly with the surface of a flat. The square meter gets cheaper for large flats, most probably because fix costs like installing a kitchen and having a parking lot stay the same for all sizes of flats.\n",
    "\n",
    "We finally plot the two factors (distance and surface) in a pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = rent_distances[[\"distance\", \"surface\", \"CHF/m2\"]]\n",
    "plot_df.columns = [\n",
    "    \"distance from the port Ouchy in km\", \n",
    "    \"surface of the flat\", \n",
    "    \"rent price in CHF/m^2\"\n",
    "]\n",
    "\n",
    "pair = sns.pairplot(\n",
    "    plot_df, \n",
    "    x_vars=[\"distance from the port Ouchy in km\", \"surface of the flat\"], \n",
    "    y_vars=[\"rent price in CHF/m^2\"],\n",
    "    height=6,\n",
    "    aspect=1,\n",
    "    kind=\"reg\"\n",
    ");\n",
    "pair.fig.suptitle(\"Rent price relationships\");\n",
    "plt.savefig(\"export/distance.svg\", format=\"svg\") # export in SVG to be compatible with the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Predict prices for all parcelles \n",
    "\n",
    "We want now find the prices (CHF/m2) of rents for all parcels. To do that we use the *k-nearest-neighbor* ML-algorithm provided by *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be trained\n",
    "train = rent_prices_pd[['CHF/m2', 'long', 'lat']].copy()\n",
    "train.rename({'CHF/m2':'target'},axis='columns',inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each parcelle, find longitude and latitude, consideting the center of the Polygons\n",
    "all_owners_parcelles_pd['long'] = all_owners_parcelles_pd['geometry'].apply(lambda poly: poly.centroid.x)\n",
    "all_owners_parcelles_pd['lat'] = all_owners_parcelles_pd['geometry'].apply(lambda poly: poly.centroid.y)\n",
    "predict = all_owners_parcelles_pd[['parc_num', 'long', 'lat']].copy()\n",
    "predict.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict parcelles prices using `model_price_knn` method defined in [`machine_learning.py`](/edit/machine_learning.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict prices\n",
    "from machine_learning import model_price_knn\n",
    "\n",
    "predicted_chfm2, rmse, ks = model_price_knn(train, predict, np.arange(1, 50))\n",
    "\n",
    "pd.DataFrame(rmse, ks).plot(legend=False);\n",
    "plt.xlabel(\"k\");\n",
    "plt.ylabel(\"rmse\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot show the *root mean square error* for different hyperparameters K. Once the best K is found, the K-NN algorithm is executed again on all data to find the most realistic result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export the maps with all prices by parcelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_owners_parcelles_pd['CHF/m2'] = predicted_chfm2\n",
    "all_owners_parcelles_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save heatmap with prices for each parcelle\n",
    "from heatmap import parcelles_prices\n",
    "m = parcelles_prices(all_owners_parcelles_pd.dropna())\n",
    "m.save('export/parcelles_prices.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/parcelles_prices.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Price by quartier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find out the median price for each quartier taking into account all prices of the parcelles predicted in the previous section.\n",
    "\n",
    "For a correct rendering, we want to print only the quartiers from where we scraped the data. We therefore remove the two quartiers without data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '90 - Zones foraines' and '17 - Beaulieu / Grey / Boisy from quartiers\n",
    "quartiers_to_drop = (quartiers_pd['Name'] == '17 - Beaulieu / Grey / Boisy') | \\\n",
    "                    (quartiers_pd['Name'] == '90 - Zones foraines')\n",
    "scraped_quartiers_pd = quartiers_pd[~quartiers_to_drop].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute now the media price for each quartier considering all parcelles. We consider the *median* and not the *mean* because there may be some outliers on our data since the data comes from different website and we don't have any certitude about the data pubblished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each parcelle, compute quartier\n",
    "all_owners_parcelles_pd['quartier'] = \\\n",
    "    all_owners_parcelles_pd[['lat', 'long']] \\\n",
    "    .apply(lambda row: get_quartier(row['lat'], row['long']), axis='columns')\n",
    "\n",
    "# group by quartier\n",
    "price_by_quartier = all_owners_parcelles_pd[['CHF/m2', 'quartier']] \\\n",
    "                        .groupby('quartier').agg('median')\n",
    "price_by_quartier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge the `scraped_quartiers_pd` that contains the geometry of the quartiers with `price_by_quartier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge scraped quartiers with price_by_quartier\n",
    "scraped_quartiers_pd = scraped_quartiers_pd.merge(price_by_quartier, left_on='Name', right_index=True)\n",
    "scraped_quartiers_pd.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import parcelles_prices_by_quartiers\n",
    "m = parcelles_prices_by_quartiers(scraped_quartiers_pd)\n",
    "m.save('export/parcelles_prices_by_quartiers.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/parcelles_prices_by_quartiers.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the resulting map, we can notice that quartiers close to the lake generally are more expensive. This is consistent with the conclusion we found in the 'linear regression by distance' section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Denoising owner type\n",
    "\n",
    "We want to revisit the colorful owner types map by trying to find spatial clusters with a certain ownership type.\n",
    "We will approach this problem as a denoising one, and we will attribute to each parcel an owner type which is given by the category the most represented in its local neighborhood.\n",
    "\n",
    "For each parcel, we therefore find all the parcels within a distance R (the _radius_). We will calculate the prevalent owner type within that radius and reassign it as the parcel owner type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The positions are in degrees. To accurately calculate distances we need to correct\n",
    "# by the local linearization of the number of meters per degree of latitude/longitude in lausanne\n",
    "\n",
    "EARTH_RADIUS_METERS = 6.3e6\n",
    "\n",
    "# lausanne is approximately at pi/4 degrees north (46° something)\n",
    "meters_per_easting_degree = 2*(EARTH_RADIUS_METERS*np.sin(np.pi/4))*np.pi/360\n",
    "meters_per_northing_degree = 2*EARTH_RADIUS_METERS*np.pi/360\n",
    "\n",
    "def compute_distance(delta_east, delta_north):\n",
    "    \"\"\"distance in meter given difference in coordinates\"\"\"\n",
    "    return np.sqrt((delta_east*meters_per_easting_degree)**2 +\\\n",
    "        (delta_north*meters_per_northing_degree)**2)\n",
    "\n",
    "def polygons_intersection(poly):\n",
    "    \"\"\"returns a function that gives the intersection areas of a serie of polygons with `poly`\"\"\"\n",
    "    def inters(serie):\n",
    "            return serie['geometry'].intersection(poly).area\n",
    "    return inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cells takes a couple of minutes to run\n",
    "\n",
    "RADIUS = 100\n",
    "\n",
    "polygons_df = complete_owners_parcelles_pd[['parc_num', 'owner', 'geometry', 'owner_type']]\n",
    "\n",
    "# cache this for performance purposes\n",
    "polygons_df['x'] = polygons_df['geometry'].centroid.x\n",
    "polygons_df['y'] = polygons_df['geometry'].centroid.y\n",
    "\n",
    "# prepare the serie to store the results\n",
    "own_types = polygons_df[['parc_num', 'owner_type']].copy().set_index('parc_num').sort_index()['owner_type']\n",
    "\n",
    "# iterate over every parcel\n",
    "for (idx, (parc_no, proprio, poly, owner_type, x, y)) in polygons_df.iterrows():\n",
    "    distances = compute_distance(polygons_df['x'] - x, polygons_df['y'] - y)\n",
    "    # select the cells whose center is closer than RADIUS to the current one\n",
    "    neigh = distances[distances < RADIUS]\n",
    "    \n",
    "    # now weight each neighbour contribution by the size of their intersecting area with\n",
    "    # the circle of radius RADIUS\n",
    "    circle = poly.centroid.buffer(RADIUS/meters_per_easting_degree)\n",
    "    neighbor_parcels = pd.concat((polygons_df, neigh), axis='columns', join='inner')\n",
    "    neighbor_parcels['intersection'] = neighbor_parcels.apply(polygons_intersection(circle), axis='columns')\n",
    "    intersection_per_cat = neighbor_parcels.groupby('owner_type')['intersection'].sum()\n",
    "    own_types.loc[parc_no] = intersection_per_cat.sort_values().index[-1]\n",
    "    \n",
    "m = by_owners_category(complete_owners_parcelles_pd, own_types.to_frame())  \n",
    "m.save(\"export/by_owners_category_denoised.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_types.to_frame().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/by_owners_category_denoised.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Entropy map\n",
    "\n",
    "To study local monopolies of ownership of the land, we produce an entropy map that will seek to detect areas where the owners in a local neighborhood of parcls are few.\n",
    "To do this we select the nearest neighbors of each parcels, and calculate the Shannon entropy of the distribution of owners in this neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cells takes a couple of minutes to run\n",
    "\n",
    "def polygons_intersection(poly):\n",
    "    def inters(serie):\n",
    "            return serie['geometry'].intersection(poly).area\n",
    "    return inters\n",
    "\n",
    "K = 10\n",
    "RADIUS = 100\n",
    "\n",
    "polygons_df = complete_owners_parcelles_pd[['parc_num', 'owner', 'geometry', 'owner_type']]\n",
    "\n",
    "# cache this for performance purposes\n",
    "polygons_df['x'] = polygons_df['geometry'].centroid.x\n",
    "polygons_df['y'] = polygons_df['geometry'].centroid.y\n",
    "# prepare the serie to store the results\n",
    "entropy = polygons_df[['parc_num', 'owner']].copy().set_index('parc_num').sort_index()['owner']\n",
    "\n",
    "for (idx, (parc_no, proprio, poly, owner_type, x, y)) in polygons_df.iterrows():\n",
    "    distances = compute_distance(polygons_df['x'] - x, polygons_df['y'] - y)\n",
    "    # select the cells whose center is closer than RADIUS to the current one\n",
    "    neigh = distances.sort_values(ascending=True)[:K]\n",
    "    # now weight each neighbour contribution by the size of their intersecting area with\n",
    "    # the circle of radius RADIUS\n",
    "#     circle = poly.centroid.buffer(RADIUS/meters_per_easting_degree)\n",
    "    neighbor_parcels = pd.concat((polygons_df, neigh), axis='columns', join='inner')\n",
    "#     neighbor_parcels['intersection'] = neighbor_parcels.apply(polygons_intersection(circle), axis='columns')\n",
    "    intersection_per_owner = neighbor_parcels.groupby('owner').size()\n",
    "    p = intersection_per_owner / intersection_per_owner.sum()\n",
    "    entropy.loc[parc_no] = scipy.stats.entropy(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import entropy_owners\n",
    "m = entropy_owners(complete_owners_parcelles_pd._to_geo(), entropy)\n",
    "m.save(\"export/entropy_owners.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/entropy_owners.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data for website\n",
    "\n",
    "Yet that we have all data, we can prepare ad-hoc maps to be posted on our final website.\n",
    "\n",
    "The first map show owners by type of category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import by_owners_all_in_one\n",
    "m = by_owners_all_in_one(\n",
    "    complete_owners_parcelles_pd._to_geo(),\n",
    "    parcels_categories, own_types.to_frame(), quartiers_pd._to_geo())\n",
    "m.save(\"export/by_owners_all_in_one.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/by_owners_all_in_one.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import by_rents_all_in_one\n",
    "m = by_rents_all_in_one(rent_prices_pd, scraped_quartiers_pd, all_owners_parcelles_pd.dropna())\n",
    "m.save(\"export/by_rents_all_in_one.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting map is accessible [here](export/by_rents_all_in_one.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Our final goal has been to try to understand the relation between real estate owners and price. \n",
    "\n",
    "After scraping, parsing and cleaning the data from the cadastre of Lausanne and the rent prices of different rent portals, we went through different phase to try to find as many relations and links as possible. Muliple models such has linear regression or k-nearest-neighbour have been used to verify or prove our assumptions. \n",
    "\n",
    "From the most important results a data-driven story has born and can be found at the following address: [Who owns Lausanne?](https://who-owns-lausanne.github.io/).\n",
    "\n",
    "Thanks for reading. \n",
    "\n",
    "Jonathan, Pietro and Yann."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
