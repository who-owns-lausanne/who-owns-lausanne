{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who owns Lausanne? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "In order to run this notebook you will need multiple dependecies. We assume you have a running `conda` distribution.\n",
    "\n",
    " - `numpy` needs to be in version `>=0.15`\n",
    " - The JSON processing tool `jq` is needed. Install with your OS' package manager (e.g. `brew install jq`).\n",
    " - `pip install yq geopy shapely`\n",
    " - If you want to have a look at the raw geographical data you have to intall [QGIS](https://www.qgis.org/en/site/), an open source geo information system tool.\n",
    "\n",
    "_If you are running an older version of macOS (e.g. 10.11) you might need to call `ulimit -n 1024` in the terminal before starting `jupyter`. This can avoid a bug with one of the preprocessing scripts._\n",
    "\n",
    "## 1. Public data and owners\n",
    "\n",
    "We obtained ftp access from the Lausanne office of cadastre. The data is a collection of ESRI shapefiles, describing roads, buildings, parcels, trees, waterbodies, and others.\n",
    "Each shapefile is a collection of features, and each feature has an associated geometry (e.g. the shape of a land parcel) and associated attributes ( e.g. the commune responsible for the parcel, the parcel number).\n",
    "\n",
    "We can explore this dataset by using GIS software that supports shapefiles. We used QGIS to explore the dataset.\n",
    "We hoped to find an attribute describing the parcel owner in the parcel shapefile layer, but it wasn't there.\n",
    "We had to resort to web scraping to recover this attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Scraping owners\n",
    "\n",
    "### 1.1.2 Download XML files\n",
    "We wanted to associate each parcel in Lausanne to an owner. To do this, we divided Lausanne's surface in rectangles, and requested parcel informations for these rectangles to a service exposing the owners name.\n",
    "The code for the scraping is in [`/scraping/owners/scrape_owners_to_xml.py`](/edit/scraping/owners/scrape_owners_to_xml.py).\n",
    "\n",
    "The result of owner scraping is a set of 400 xml files, each containing parcel information for a geographical rectangle. The data are saved in the following directory: `data/raw/owners/`.\n",
    "\n",
    "For privacy reason we decided not to push any data on the online github respository.\n",
    "\n",
    "We start exploring the raw owner xml data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"data/raw/owners/\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file is named after the coordinates, in the Swiss systems, of the top-left and bottom-right points bounding the scraped rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"data/raw/owners/\" 2>/dev/null | head -10 # suppress error message by redirecting errors to null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 20 \"data/raw/owners/534810.4210526316_155847.0_535161.3710526315_155589.0.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 From XML to a single JSON\n",
    "We use `yq`, `xq` and `jq` programs to extract only the features we care about from the different XML files and save them as a list of objects in a single json file.\n",
    "[`scraping/owners/multiple_xml_to_single_json.sh`](/edit/scraping/owners/multiple_xml_to_single_json.sh) is a small script leveraging the expressiveness of `jq` to efficiently concatenate the XML files into a single json, while also discarding all the attributes we have no interest in.\n",
    "\n",
    "The result file of the shell program is a JSON file`/data/owners/all_owners_dirty.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all XML into one JSON file\n",
    "!scraping/owners/multiple_xml_to_single_json.sh all_owners_dirty.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see errors of the form\n",
    "```\n",
    "jq: error (at <stdin>:1): Cannot iterate over null (null)\n",
    "```\n",
    "you don't have to worry. These are just errors, when `jq` encounters the end of a file. The script is still working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Remove duplicated and  clean owners JSON\n",
    "The generated `all_owners_dirty.json` JSON has duplicate entries, entries concerning other communes than Lausanne and entries with missing owners. Furthermore, JSON is not the best format to handle tabular data. The code in [`scraping/owners/owner_json_to_clean_csv.py`](/edit/scraping/owners/owner_json_to_clean_csv.py) cleans the duplicates and tranfsorms the data into `all_owners.csv` CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dirty data and write it to 'all_owners.csv' \n",
    "import scraping.owners\n",
    "scraping.owners.owner_json_to_clean_csv.main(\n",
    "    './data/owners/all_owners_dirty.json',\n",
    "    './data/owners/all_owners.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Joining the owners data with the cadastre shapefiles\n",
    "The result of the previous preprocessing steps is a CSV file with three columns: commune number, parcel number, and the owner name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_owners = pd.read_csv('data/owners/all_owners.csv')\n",
    "all_owners.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to add the owner name to the attributes of the parcels shapefile that we obtained from \"Office du Cadastre\". To do so, we import the csv and the shapefile in QGIS, and we join this two \"tables\" by parcel number. The resulting geographical layer contains all the geographical features representing the parcels, and additionally the owner name for each parcel. \n",
    "\n",
    "We can now export this layer as a GeoJSON, making sure to use `WGS-84` as the coordinate system, and continue our exploration.\n",
    "\n",
    "The exported *geojson* file is saved at `data/owners/all_owners_parcelles.geojson`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Cadastral data - data exploration\n",
    "\n",
    "We now have a GeoJSON, containing parcel geometries and parcel owners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start loading the `geojson` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/owners/all_owners_parcelles.geojson') as geojson:\n",
    "    all_owners_parcelles = json.load(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_owners_parcelles.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information we need are located into features column. Such columns is a list of properties where each properties contains the owners, the localization the intereted area (geometry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(all_owners_parcelles['features'][6], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the attributes of each geographical feature in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 'number (id) of parcels' and owners name\n",
    "features = [\n",
    "    {'parc_num': feature['properties']['NO_PARC'],\n",
    "     'owner': feature['properties']['proprio']} for feature in all_owners_parcelles['features']\n",
    "]\n",
    "parcels = pd.DataFrame.from_records(features)\n",
    "parcels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parcels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Who is the biggest real estate owners?\n",
    "\n",
    "We can now quickly answer questions such as who are the 30 biggest property owners in Lausanne, by using the number of parcels owned as a measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_per_owner = parcels['owner'].value_counts()\n",
    "parcels_per_owner.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the biggest owners are either corporations, pension funds, or public institutions. \n",
    "\n",
    "We note that there is no a single private person in the list. This data tell us that our analysis will have to take into consideration other kind of owners than the private ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Unique owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the non assigned values, we can see the total number of parcels owned and the unique owners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners = parcels['owner'].dropna()\n",
    "print('Total parcels', len(owners))\n",
    "print('Unique owners', len(owners.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are almost 8'000 parcels in Lausanne. \n",
    "\n",
    "BWe are interestd to know how many people and societies own them. This number doesn't account for PPE (_prorpiété par étage_, single flats owned by privates). A lower bound on the owners can be estimated by discarding the PPE entries altogether:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds_owners = len(owners[~owners.str.contains('PPE ')].unique())\n",
    "print('Unique lower-bounds owners', lower_bounds_owners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lower bound for the number of owners. Although, the real number is likely to be much higher since it's unprobable that most of these unique owners are also owners of a PPE share."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Visualizing the distribution of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute portion of missing values\n",
    "parcels['owner'].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22% of the parcels don't have owner information. Indeed, many parcels reperesent roads, and as such they didn't have an owner on the site we scraped. Also we didn't scrape the values for the northern part of Lausanne, which is mostly farmland and woods.\n",
    "\n",
    "Let's try to visualize the missing values on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from tools import *\n",
    "\n",
    "!mkdir export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "\n",
    "def style_function(feature):\n",
    "    \"\"\"Returns color red for missing values, blue for valid.\"\"\"\n",
    "    return {\n",
    "        'fillColor':\n",
    "        'red' if feature['properties']['proprio'] is None else 'blue', \n",
    "        'stroke': False\n",
    "    }\n",
    "\n",
    "geo_fol = folium.GeoJson(all_owners_parcelles, style_function=style_function)\n",
    "\n",
    "m.add_child(geo_fol)\n",
    "m.save('export/missing_values.html')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization is not very snappy or legible, but we can interpret it as follows:\n",
    "\n",
    "- Red areas are parcels for which the proprietary is not assigned, i.e `None`. The northern parts of Lausanne were not scraped, since we didn't want to overload the scraped website and since they're mostly rural areas. It is expected that they are red.\n",
    "- Zooming into central Lausanne, we see that roads have unknown owners. This is also expected.\n",
    "- For some areas blue and red overlap, yielding purple parcels. This is because the dataset is slightly dirty and some bigger parcels with no owners _contains_ smaller parcels with known owners. Therefore the colors overlap.\n",
    "\n",
    "Having asserted that the dataset is fairly sane, we can drop the features were the owner is `None`, since they will be of no use to us (roads), and will make the map drawing slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_parcels = all_owners_parcelles.copy()\n",
    "\n",
    "# replace the list of features by filtering out the \n",
    "# features having None as proprio\n",
    "geo_parcels['features'] = [\n",
    "    feature for feature in geo_parcels['features']\n",
    "    if feature['properties']['proprio'] is not None\n",
    "]\n",
    "\n",
    "features = [\n",
    "    {'parc_num':feature['properties']['NO_PARC'],\n",
    "    'owner':feature['properties']['proprio']} for feature in geo_parcels['features']\n",
    "]\n",
    "parcels = pd.DataFrame.from_records(features)\n",
    "len(parcels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2.4 Show parcels by owner type\n",
    "\n",
    "The parcel owner format allows us to know the category of each owner. \n",
    "We will use similar categories as the statistical office of the city of Lausanne [here](https://www.lausanne.ch/officiel/statistique/quartiers/tableaux-donnees.html):\n",
    "\n",
    "- privates\n",
    "- public institutions\n",
    "- companies (corporations)\n",
    "- cooperatives\n",
    "- pension funds\n",
    "- foundations\n",
    "- PPE\n",
    "\n",
    "Societies are detected by having 'AG' or 'SA' in their name. Similary for cooperatives, foundations, and pension funds. We display a map colored by the owner category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def categorize(owner):\n",
    "    regex_cats = [\n",
    "            ('retraites|pension|prévoyance|prevoyance|BVK|'+\\\n",
    "             'anlagestiftung|fondation d\\'investissement|fondation de placement|'+\\\n",
    "             'vorsorge|anlage stiftung', 'pension'),\n",
    "            ('commune de lausanne|dfire|cff|domaine public|Etat de Vaud|Service du logement', 'public'),\n",
    "            (r's\\.a\\.|\\bsa\\b|\\bag\\b|société anonyme|sàrl|\\bBCV\\b|SICAV', 'société'), # BCV société ou public?\n",
    "            (r'fondation|\\bstiftung|foundation|association|fédération', 'fondation/association'),\n",
    "            (r'\\bppe\\b|copropriété|copropriete|parcelles', 'PPE'),\n",
    "            ('société coopérative|societe cooperative', 'coop'),\n",
    "            ('.*', 'private')\n",
    "    ]\n",
    "    for cat_re, category in regex_cats: \n",
    "        if re.search(cat_re, owner, flags=re.IGNORECASE):\n",
    "            return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_categories = parcels[['owner']]\n",
    "owners_categories['category'] = owners_categories['owner'].apply(categorize)\n",
    "owners_categories = owners_categories.drop_duplicates().set_index('owner')\n",
    "owners_categories.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "\n",
    "def style_function(feature):\n",
    "    colors = {\n",
    "        'coop': 'yellow',\n",
    "        'société' : 'red',\n",
    "        'public' : 'green',\n",
    "        'private': 'blue',\n",
    "        'PPE': 'orange',\n",
    "        'pension': 'purple',\n",
    "        'fondation/association' : 'brown'\n",
    "        \n",
    "    }\n",
    "    owner = feature['properties']['proprio']\n",
    "    cat = owners_categories.loc[owner][0]\n",
    "    \n",
    "    return {\n",
    "        'stroke':False,\n",
    "        'fillColor': colors[cat]\n",
    "    }\n",
    "\n",
    "folium.GeoJson(\n",
    "    geo_parcels, \n",
    "    style_function=style_function,\n",
    "    # show the owner at hover\n",
    "    tooltip=folium.GeoJsonTooltip(['proprio'])\n",
    ").add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rents data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scraping\n",
    "\n",
    "In order to analyse how ownership patterns influence prices, we needed to complement the owners dataset with rent prices.\n",
    "Rent prices are generally not public, but we can scrape from real estate websites' current rent listings, and extract the prices from there.\n",
    "\n",
    "We scraped from [anibis.ch](https://www.anibis.ch/fr/default.aspx), [homegate.ch](https://www.homegate.ch/fr) and [tutti.ch](https://tutti.ch) and extracted up-to-date real estate announcements.\n",
    "\n",
    "#### 2.1.1 Download the raw rents data\n",
    "\n",
    "The scripts to download the data from the three portals are the following:\n",
    "\n",
    "- for homegate: [`scraping/homegate/scrape_homegate.py`](/edit/scraping/homegate/scrape_homegate.py), to download and parse the data. Data are saved in `data/rents` as `homegate.json`\n",
    "\n",
    "- for anibis:\n",
    "    1. [`scraping/anibis/anibis_scrape_listings.py`](/edit/scraping/anibis/anibis_scrape_listings.py) to download the index of results matching rents in lausanne\n",
    "    2. [`scraping/anibis/anibis_scrape_offers.py`](/edit/scraping/anibis/anibis_scrape_offers.py) to download each single rent offer, given a parsed index\n",
    "\n",
    "- for tutti:\n",
    "    1. [`scraping/tutti/tutti_scrape_listings.py`](/edit/scraping/tutti/tutti_scrape_listings.py) to download the index of results matching rents in lausanne\n",
    "    \n",
    " \n",
    "The raw rents data are then saved in `data/raw`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Parse the rents data\n",
    "\n",
    "\n",
    "Once downloaded we parse the data in a agreed JSON format.\n",
    "\n",
    "#### Tutti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.tutti import tutti_parse_listings\n",
    "tutti_parse_listings.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anibis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`scraping/anibis/anibis_parse_listings.py`](/edit/scraping/anibis/anibis_parse_listings.py) to parse the listings index.\n",
    "2. [`scraping/anibis/anibis_parse_offers.py`](/edit/scraping/anibis/anibis_parse_offers.py) to parse the pages for each offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Removing duplicates\n",
    "\n",
    "Most rent listings are published on several websites. When merging the data sources, we first need to figure out which results are present in multiple datasets to avoid duplicate datapoints. We consider listings to be duplicates if they have the same address and the same price. The code is in [`cleaning/merge_rent_offers.py`](/edit/cleaning/merge_rent_offers.py) .\n",
    "In addition to removing duplicates, the merging script does cleaning of offers without prices, without addresses, or without surface area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jq length data/raw/rents/tutti.json\n",
    "!jq length data/raw/rents/anibis_with_streets.json\n",
    "!jq length data/raw/rents/homegate.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before cleaning and merging we have a total of ~1200 offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tutti = pd.read_json(\"./data/raw/rents/tutti.json\")\n",
    "pd_tutti.replace('nan',np.nan, inplace=True)\n",
    "\n",
    "pd_tutti.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_anibis = pd.read_json(\"./data/raw/rents/anibis_with_streets.json\")\n",
    "pd_anibis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_homegate = pd.read_json(\"./data/raw/rents/homegate.json\")\n",
    "pd_homegate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleaning as cleaning\n",
    "filenames = [\"./data/raw/rents/tutti.json\", \n",
    "             \"./data/raw/rents/anibis_with_streets.json\",\n",
    "            \"./data/raw/rents/homegate.json\"]\n",
    "merged = cleaning.merge_rent_offers.main(filenames)\n",
    "len(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mapping street addresses to coordinates\n",
    "The data cleaning up to now provided us with a list of json objects, each one representing a rent offer.\n",
    "\n",
    "The address is in textual form. Also, it is clear that there will be more cleaning needed. The first address is a phone number instead of an actual address. This sanitisation is automatically provided by the next script.\n",
    "\n",
    "To perform geographical queries on addresses, we need to convert them to coordinates. To do so, we use the cadastral layer of building addresses, provided by the Cadastral offic of Lausanne.\n",
    "During merging of the three datasets, the addresses were standardized to use the format used by this cadastral layer.\n",
    "\n",
    "To map an address to a coordinates couple, we iterate over all buildings in Lausanne, and check if the street name and the street number match those of our address. If there's a match, we extract the coordinates of the building from the cadastral layer. If there isn't we drop the offer (like the phone number above) and therefore perform some cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_prices = cleaning.address_to_coords.main(merged)\n",
    "len(rent_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_rent_prices = pd.DataFrame.from_dict(rent_prices)\n",
    "# DROP not used columns\n",
    "pd_rent_prices.drop(['city', 'meuble'], axis='columns', inplace=True)\n",
    "\n",
    "pd_rent_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete eventually left duplicates\n",
    "# TODO\n",
    "\n",
    "pd_rent_prices['street'] = pd_rent_prices['street'].str.lower()\n",
    "pd_rent_prices['price'] = pd_rent_prices['price'].astype(float)\n",
    "\n",
    "duplicate = pd_rent_prices.groupby(['street','number','price'])['address'].transform('count') > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the rents dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take a first look at the rental data in a cleaned form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the geojson featuring borders for each quartier\n",
    "quartiers = json.load(open('data/raw/maps/quartiers.geojson'))\n",
    "\n",
    "# compute the cost per squared meter of the rent\n",
    "for offer in rent_prices:\n",
    "    offer['CHF/m2'] = float(offer['price'])/float(offer['surface'])\n",
    "    \n",
    "# draw a map showing the location of each vacancy, and the quartiers borders\n",
    "m = getMap()\n",
    "folium.GeoJson(quartiers).add_to(m)\n",
    "for offer in rent_prices:\n",
    "    coords = offer['position']\n",
    "    # Marker wants first the N coordinate and then E\n",
    "    folium.Marker((coords[1], coords[0]), tooltip=offer['CHF/m2']).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Mapping rent datapoints to quartiers\n",
    "Each rent data-point has a pair of coordinates localizing it in space. _quartiers_ are polygons, whose perimeter is a list of coordinates. We can use the python library `shapely`, that allows us to perform geometrical queries, to find the _quartier_ for each rent offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the two data structures needed\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "for offer in rent_prices:\n",
    "    offer['quartier'] = None\n",
    "    for quartier in quartiers['features']:\n",
    "        \n",
    "        # skip because we don't have owner data for forest areas\n",
    "        if quartier['properties']['Name'] == '90 - Zones foraines':  \n",
    "            continue\n",
    "        \n",
    "        offer_pos = Point(offer['position'])\n",
    "        \n",
    "        # we extract the list of coordinates of the polygon's vertices, \n",
    "        # discarding useless height\n",
    "        quartier_vertices = [(east, north) for east, north, z in quartier['geometry']['coordinates'][0]]\n",
    "        quartier_poly = Polygon(quartier_vertices)\n",
    "        if quartier_poly.contains(offer_pos):\n",
    "            offer['quartier'] = quartier['properties']['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check by changing the color of the marker depending on the found _quartier_ and displaying all of it on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "folium.GeoJson(quartiers).add_to(m)\n",
    "for offer in rent_prices:\n",
    "    coords = offer['position']\n",
    "    \n",
    "    # little hack to assign a different color to each quartier\n",
    "    # calculate hex color from a hash of the name\n",
    "    color = '%06x' % (hash(offer['quartier']) % (256**3))\n",
    "    \n",
    "    # Marker wants first the N coordinate and then E\n",
    "    folium.CircleMarker(\n",
    "        (coords[1], coords[0]),\n",
    "        radius=5, fill_color='#'+color, weight=0, fill_opacity=1\n",
    "    ).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good. We will now give a first statistic on rent prices. **However**, there are still fake offers (like offers for parking lots and the like) and there are still outliers in the dataset. The results are therefore not yet _real, clean means_. \n",
    "\n",
    "As a cheap mitigation we will display the median instead of the mean. Before analysing and building our mathematical model we will however clean those offers out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display median price per neighborhood\n",
    "rents_per_quartier = pd.DataFrame.from_dict(rent_prices)\n",
    "rents_per_quartier[['CHF/m2', 'quartier']].groupby('quartier').agg('median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Map each offer to an owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each parcel has an owner and a geometry, which is a `MultiPolygon`. A `MultiPolygon` is a list of `Polygon`s. Every `Polygon` is a list of \"linear rings\". The first linear ring defines the outer perimeter of the polygon, and the next linear rings define holes in the polygon.\n",
    "For all parcels the multipolygons are made of only 1 polygon, and every polygon only has the outer perimeter and no holes. We can use shapely polygons again to find wether an offer is within a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each parcels, construct a Polygon\n",
    "def get_parcel_polygons():\n",
    "    parcel_polygons = []\n",
    "    for parcel in geo_parcels['features']:\n",
    "        coords = parcel['geometry']['coordinates'][0][0]\n",
    "        num_parc = parcel['properties']['NO_PARC']\n",
    "        proprio = parcel['properties']['proprio']\n",
    "        poly = Polygon(coords)\n",
    "        parcel_polygons.append((num_parc, proprio, poly))\n",
    "    return parcel_polygons\n",
    "parcel_polygons = get_parcel_polygons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each offer, assign a propretary\n",
    "for offer in rent_prices:\n",
    "    offer_pos = Point(offer['position'])\n",
    "    for parc_n, proprio, poly in parcel_polygons:\n",
    "        if poly.contains(offer_pos):\n",
    "            offer['proprio'] = proprio\n",
    "    if 'proprio' not in offer:\n",
    "        offer['proprio'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate but how can one tell?\n",
    "#[o for o in rent_prices if o['proprio'] is not None and 'Meuli' in o['proprio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER: CFF est propriétaire de Avenue de Sévelin 13 mais pas de 13 A-E. Nécessite meilleure parsing\n",
    "# des addresse pour ne pas faire de ces erreures.\n",
    "#[o for o in rent_prices if o['proprio'] is not None and 'CFF' in o['proprio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([o for o in rent_prices if o['proprio'] is None])\n",
    "# datapoints in zone foraine. We didn't scrape the owners for that quartier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rent_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear model describing relation of ownership and price\n",
    "\n",
    "The data is now in the form we need in order to apply our model. As our main goal is to understand the rent price composition, we will perform linear regression on the rent prices.\n",
    "\n",
    "More precisely, we will try to predict the prices of rents in each quartier based on the features:\n",
    "\n",
    " - ownership proportion of each ownership type: ($f_{public}, f_{s.a.}, $...)\n",
    " - distance from the centre of the city: $dist$\n",
    " - the mean price of rents in the _quartier_ $q$ (dependent variable): $price(q)$ \n",
    " \n",
    "The linear model is then:\n",
    "\n",
    "$$\n",
    "price(q) = \\beta_1 f_{public}(q) + \\beta_2  f_{s.a.}(q) + ~...~ + \\beta_j  f_{privates}(q)+  \\beta_k dist(q)\n",
    "$$\n",
    "\n",
    "We will apply linear regression to this model and extract the knowledge from the parameters $\\beta$. One problem could however be, that the ownership pattern itself depends on the distance or vice-versa. In that case we'll be able to check this assumption by predicting the distance from the ownership types:\n",
    "\n",
    "$$\n",
    "dist(q) = \\beta_1 f_{public}(q) + \\beta_2  f_{s.a.}(q) + ~...~ +\\beta_j  f_{privates}(q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 influence of owner type on average price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import scipy\n",
    "\n",
    "covariates = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"owner_type\": categorize(offer[\"proprio\"]),\n",
    "            \"price/m2\": offer[\"CHF/m2\"],\n",
    "        }\n",
    "        for offer in rent_prices\n",
    "        if offer[\"proprio\"] is not None\n",
    "    ]\n",
    ")\n",
    "covariates[\"owner_type\"] = covariates[\"owner_type\"].astype(\"category\")\n",
    "samples_per_cat = covariates[\"owner_type\"].value_counts()\n",
    "\n",
    "covariates = pd.get_dummies(covariates)\n",
    "\n",
    "# drop one indicator to avoid multiple colinearity\n",
    "covariates = covariates.drop(\"owner_type_private\", axis=\"columns\")\n",
    "\n",
    "coeffs = np.empty(covariates.shape)\n",
    "\n",
    "# columns: num of covariates minus the response (y) plus 1 for the intercept\n",
    "\n",
    "# bootstrap confidence interval for linear regression coefficients\n",
    "for i in range(covariates.shape[0]):\n",
    "    sample = covariates.values[\n",
    "        np.random.choice(\n",
    "            covariates.shape[0], size=covariates.shape[0], replace=True\n",
    "        )\n",
    "    ]\n",
    "    lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "    X = sample[:, 1:]\n",
    "    y = sample[:, 0]\n",
    "    lm.fit(X, y)\n",
    "    coeffs[i, 0] = lm.intercept_\n",
    "    coeffs[i, 1:] = lm.coef_\n",
    "\n",
    "lower, upper = np.percentile(coeffs, q=(2.5, 97.5), axis=0)\n",
    "\n",
    "print(\"%-40s\\t%s\\t%s\\t%s\" % (\"feature\", \".025 qtile\", \".975 qtile\", \"n\"))\n",
    "print()\n",
    "print(\"%-40s:\\t%f\\t%f\" % (\"intercept\", lower[0], upper[0]))\n",
    "\n",
    "for typ, lower_q, upper_q in zip(covariates.columns[1:], lower[1:], upper[1:]):\n",
    "    print(\n",
    "        \"%-40s:\\t%f\\t%f\\t%d\"\n",
    "        % (typ, lower_q, upper_q, samples_per_cat[typ.split(\"_\")[-1]])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression on distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import great_circle\n",
    "\n",
    "position = 46.50766, 6.62758\n",
    "\n",
    "rent_positions = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"lat\": offer[\"position\"][1],\n",
    "            \"long\": offer[\"position\"][0],\n",
    "            \"CHF/m2\": offer[\"CHF/m2\"],\n",
    "        }\n",
    "        for offer in rent_prices\n",
    "    ]\n",
    ").dropna()\n",
    "\n",
    "rent_distances = rent_positions.apply(\n",
    "    lambda row: great_circle((row.lat, row.long), position).km, axis=1\n",
    ")\n",
    "rent_distances = rent_distances.to_frame(\"km\")\n",
    "rent_distances[\"CHF/m2\"] = rent_positions[\"CHF/m2\"]\n",
    "rent_distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"km\", y=\"CHF/m2\", data=rent_distances);\n",
    "plt.title(\"Distance from the station vs. rent prices\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_model = scipy.stats.linregress(\n",
    "    rent_distances.km, rent_distances[\"CHF/m2\"]\n",
    ")\n",
    "\n",
    "def print_model(model):\n",
    "    for stat in [\"intercept\", \"slope\", \"stderr\", \"pvalue\"]:\n",
    "        print(stat, \": \", getattr(model, stat))\n",
    "\n",
    "        \n",
    "print_model(distance_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_model = scipy.stats.linregress(\n",
    "    rent_positions.lat ** 2, rent_positions[\"CHF/m2\"]\n",
    ")\n",
    "long_model = scipy.stats.linregress(\n",
    "    rent_positions.long ** 2, rent_positions[\"CHF/m2\"]\n",
    ")\n",
    "\n",
    "print_model(lat_model)\n",
    "print()\n",
    "print_model(long_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents_per_quartier = pd.DataFrame.from_records(\n",
    "    [\n",
    "        {\n",
    "            \"lat\": offer[\"position\"][1],\n",
    "            \"long\": offer[\"position\"][0],\n",
    "            \"CHF/m2\": offer[\"CHF/m2\"],\n",
    "            \"surface\": float(offer[\"surface\"]),\n",
    "            \"proprio\": offer[\"proprio\"],\n",
    "            \"quartier\": offer[\"quartier\"],\n",
    "        }\n",
    "        for offer in rent_prices\n",
    "    ]\n",
    ")\n",
    "\n",
    "rents_per_quartier[\"distance\"] = rent_distances.km\n",
    "rents_per_quartier = rents_per_quartier.dropna()\n",
    "\n",
    "print_model(\n",
    "    scipy.stats.linregress(\n",
    "        rents_per_quartier.surface, rents_per_quartier[\"CHF/m2\"]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"surface\", y=\"CHF/m2\", data=rents_per_quartier);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "Can a heatmap show spacial dependency of rent prices? Let's investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools\n",
    "tools.heatmap_prices_from_json(rent_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What comes next:\n",
    "\n",
    "Please find more information about further ideas, our current state of work and our story in the `README`.\n",
    "\n",
    "Because obtaining the data from all the different sources and with various methods is a huge amount of work in this project, we are not fully done with cleaning and analysing all of the datasets. As said before, the rental data still contains unwanted entries. And the data from tutti.ch has not yet been converted to the correct JSON format.\n",
    "\n",
    "However, while working on this and discussing the progress of the project we came up with a good guideline: understand how prices are determined. This is good because it lends itself well for writing a story but it also naturally yields the rather simple mathematical model from above. We are therefore convinced that we will be able to carry out the analysis to its full extent and to come up with a good web data story in the end!\n",
    "\n",
    "### Todos and future sections:\n",
    "\n",
    " - Adapt ownership categories\n",
    " - Clean fake offers and outliers\n",
    " - Linear regression on data and analysis\n",
    "     - Tune model\n",
    "     - extract parameters and CIs\n",
    "     - intra-quartier effects\n",
    "     - ...\n",
    " - Political analysis by hand\n",
    " - Check: do we answer the four RQs?\n",
    " - Graphics and maps production for web story\n",
    " \n",
    "--> The outline for the story (our end result) can be found in the `README`.\n",
    " \n",
    " - Condense information to one line about finding affordable accommodation and why it is difficult (e.g. cheap parts are far from centre/university...)\n",
    " - Write the story\n",
    " - Design web page and animations (using a static generator and `JS`)\n",
    " - Deploy site to server (github pages or own)\n",
    " \n",
    "**Milestone 3, 16.12.18**\n",
    " \n",
    " - Boil analysis down to 5 keypoints\n",
    " - Think about way of presenting this highly geographical data/problem\n",
    " - Write text for presentation and exercise!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolate rents for all parcels with k-nearest-neighbor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be trained\n",
    "\n",
    "pd_parcels_rent = pd.DataFrame.from_dict(rent_prices)\n",
    "pd_parcels_rent.head(2)\n",
    "\n",
    "train = pd_parcels_rent['position'].apply(lambda r: pd.Series(r))\n",
    "train = pd.concat([pd_parcels_rent['CHF/m2'], train], axis='columns')\n",
    "train.columns = ['target', 'long', 'lat']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be predicted\n",
    "polygons_df = pd.DataFrame.from_records(get_parcel_polygons())\n",
    "polygons_df.columns = ('parc_no', 'proprio', 'poly')\n",
    "polygons_df['owner_type'] = polygons_df['proprio'].apply(categorize)\n",
    "polygons_df['x'] = polygons_df['poly'].apply(lambda poly: poly.centroid.x)\n",
    "polygons_df['y'] = polygons_df['poly'].apply(lambda poly: poly.centroid.y)\n",
    "\n",
    "# select 'id' and 'position' of parcels\n",
    "features = polygons_df[[\"x\", \"y\", \"parc_no\"]]\n",
    "features.columns = [\"long\", \"lat\", \"parc_no\"]\n",
    "\n",
    "predict = features[[\"lat\", \"long\"]]\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict prices\n",
    "from machine_learning import model_price_knn\n",
    "\n",
    "prices, rmse, ks = model_price_knn(train, predict, np.arange(1, 50))\n",
    "\n",
    "pd.DataFrame(rmse, ks).plot(legend=False);\n",
    "plt.xlabel(\"k\");\n",
    "plt.ylabel(\"rmse\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pandas with position and price for all parcelles\n",
    "prices_for_all_parcels = features.copy()\n",
    "prices_for_all_parcels['price'] = prices\n",
    "\n",
    "prices_for_all_parcels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save heatmap with prices for each parcelle\n",
    "hm = tools.heatmap_prices_per_parcels(geo_parcels, prices_for_all_parcels)\n",
    "hm.save('export/heatmap_prices_all_parcelles.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising owner type\n",
    "\n",
    "We want to revisit the colorful owner types map by trying to find spatial clusters with a certain ownership type.\n",
    "We will approach this problem as a denoising one, and we will attribute to each parcel an owner type which is given by the category the most represented in its local neighborhood.\n",
    "We therefore find the K nearest neighbors to a parcel (itself included), and assign as type the most represented type in the neighbors.\n",
    "\n",
    "- Find a representative point for each parcel (maybe the center of mass of the parcel)\n",
    "- For each parcel find its nearest neighbors\n",
    "- compute the distribution of ownership for each neihborhood\n",
    "- assign to the parcel the ownership in the neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "types = polygons_df[['parc_no', 'owner_type']].copy().set_index('parc_no').sort_index()['owner_type']\n",
    "for (idx, (parc_no, proprio, _, owner_type, x, y)) in polygons_df.iterrows():\n",
    "    distances2 = (polygons_df['x'] - x)**2 + (polygons_df['y'] - y)**2\n",
    "    neigh = distances2.sort_values()[:K]\n",
    "    neighbor_parcels = pd.concat((polygons_df, neigh), axis='columns', join='inner')\n",
    "    types.loc[parc_no] = neighbor_parcels['owner_type'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_df['owner_type'].value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types.value_counts().plot.pie();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = getMap()\n",
    "#TODO weight by area\n",
    "def style_function(feature):\n",
    "    colors = {\n",
    "        'coop': 'yellow',\n",
    "        'société' : 'red',\n",
    "        'public' : 'green',\n",
    "        'private': 'blue',\n",
    "        'PPE': 'orange',\n",
    "        'pension': 'purple',\n",
    "        'fondation/association' : 'brown'\n",
    "        \n",
    "    }\n",
    "    parc_num = feature['properties']['NO_PARC']\n",
    "    cat = types[parc_num]\n",
    "    \n",
    "    return {\n",
    "        'stroke':False,\n",
    "        'fillColor': colors[cat]\n",
    "    }\n",
    "\n",
    "folium.GeoJson(\n",
    "    geo_parcels, \n",
    "    style_function=style_function,\n",
    "    # show the owner at hover\n",
    "    tooltip=folium.GeoJsonTooltip(['proprio'])\n",
    ").add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price by quartier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correctly exdcute this section, please install `geopandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quartier(lat, long):\n",
    "    for quartier in quartiers['features']:\n",
    "        # skip because we don't have owner data for forest areas\n",
    "        if quartier['properties']['Name'] == '90 - Zones foraines':  \n",
    "            return None\n",
    "\n",
    "        \"\"\"Given longitute and latitude, return quartier in Lausanne\"\"\"\n",
    "        pos = Point(long, lat)\n",
    "        quartier_vertices = [(east, north) for east, north, z in quartier['geometry']['coordinates'][0]]\n",
    "        quartier_poly = Polygon(quartier_vertices)\n",
    "        if quartier_poly.contains(pos):\n",
    "            return quartier['properties']['Name']\n",
    "\n",
    "prices_for_all_parcels_with_quartiers = prices_for_all_parcels.copy()\n",
    "\n",
    "prices_for_all_parcels_with_quartiers['quartier'] = \\\n",
    "    prices_for_all_parcels_with_quartiers[['lat', 'long']] \\\n",
    "    .apply(lambda row: get_quartier(row['lat'], row['long']), axis='columns')\n",
    "\n",
    "price_by_quartiers_all = prices_for_all_parcels_with_quartiers[['price', 'quartier']].groupby('quartier').agg('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors, cm\n",
    "import branca.colormap as cmb\n",
    "\n",
    "def style_function_quartiers(feature):    \n",
    "    min_price, max_price = np.quantile(price_by_quartiers_all[\"price\"], q=(0.05, 0.90))\n",
    "\n",
    "    colormap = cmb.linear.RdYlGn_06.scale(min_price, max_price)\n",
    "    \n",
    "    # invert colors\n",
    "    colormap.colors = colormap.colors[::-1]\n",
    "    colormap.caption = \"Rent price by quartiers\"\n",
    "    \n",
    "    \n",
    "    quartier_name = feature['properties'][\"Name\"]\n",
    "    if (quartier_name == '90 - Zones foraines'):\n",
    "        price = 0\n",
    "    else:\n",
    "        price = price_by_quartiers_all.loc[quartier_name].values[0]\n",
    "        \n",
    "    return {\"stroke\": False, \"fillColor\": colormap(price), \"fillOpacity\": 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '90 - Zones foraines' from quartiers\n",
    "import geopandas\n",
    "quartiers = json.load(open('data/raw/maps/quartiers.geojson'))\n",
    "quartiers_pd = geopandas.read_file('data/raw/maps/quartiers.geojson')\n",
    "quartiers_to_drop = (quartiers_pd['Name'] == '17 - Beaulieu / Grey / Boisy') | \\\n",
    "                    (quartiers_pd['Name'] == '90 - Zones foraines')\n",
    "quartiers_dropped_pd = quartiers_pd[~quartiers_to_drop]\n",
    "\n",
    "quartiers_dropped_pd = quartiers_dropped_pd.merge(price_by_quartiers_all, left_on='Name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ = getMap()\n",
    "folium.GeoJson(quartiers_dropped_pd.to_json(), \n",
    "               style_function=style_function_quartiers,\n",
    "               tooltip=folium.GeoJsonTooltip(['price', 'Name'])\n",
    "              ).add_to(map_)\n",
    "                \n",
    "map_.save('export/price_by_quartiers_all_parcelles.html')\n",
    "map_"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
