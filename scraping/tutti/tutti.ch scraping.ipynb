{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "from numpy import char as npc\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import json\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following jupyter notebook illustrate the step tooken to scrape required real estate offers from [tutti.ch](https://www.tutti.ch/fr/li/vaud/lausanne/immobilier?o=1).\n",
    "\n",
    "For our work we only need the annoncements of real estate in the area of Lausanne.\n",
    "\n",
    "The final dataframe is saved as a CSV file named 'tutti.df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'tutti/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Go through all pages and save it locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is go through all the available pages and save the response JSON locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTutti(page, limit=100):\n",
    "    cookies = {\n",
    "        'ajs_user_id': 'null',\n",
    "        'ajs_group_id': 'null',\n",
    "        'lang': 'fr',\n",
    "        'ajs_anonymous_id': '%22bf0a3c34-c83f-4764-a48f-c783309a9f4c%22',\n",
    "        '_gcl_au': '1.1.253718592.1542968730',\n",
    "        '_ga': 'GA1.2.1357180133.1542968730',\n",
    "        '_gid': 'GA1.2.2109516043.1542968730',\n",
    "        'adw': '12a92c4c-f201-44a3-a5ce-26dbbce57a94',\n",
    "        '_gat_UA-88671020-1': '1',\n",
    "    }\n",
    "    headers = {\n",
    "        'AlexaToolbar-ALX_NS_PH': 'AlexaToolbar/alx-4.0.3',\n",
    "        'Origin': 'https://www.tutti.ch',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept-Language': 'fr',\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36',\n",
    "        'Accept': 'application/json, text/plain, */*',\n",
    "        'Referer': 'https://www.tutti.ch/fr/li/vaud/lausanne/immobilier/appartements?o=2',\n",
    "        'Connection': 'keep-alive',\n",
    "        'X-Tutti-Hash': '81fd68a0-47a0-4b8b-9401-4c63cb416c5e',\n",
    "        'X-Tutti-Source': 'web LIVE-181123-163',\n",
    "        'DNT': '1',\n",
    "    }\n",
    "    params = (\n",
    "        ('category', '1000'),\n",
    "        ('limit', limit),\n",
    "        ('m', '131'),\n",
    "        ('o', page),\n",
    "        ('region', '20'), # Region 20: lausanne\n",
    "        ('subcategory', ''),\n",
    "        ('with_all_regions', 'false'),\n",
    "    )\n",
    "\n",
    "    response = requests.get('https://api.tutti.ch/v10/list.json', headers=headers, params=params, cookies=cookies)\n",
    "    return json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJson(data, filename):\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJson(filename):\n",
    "    with open(filename, 'r') as outfile:\n",
    "        return json.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all tutti.ch advertisment from region 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute number of pages to iterate\n",
    "limit = 100\n",
    "total_ads = getTutti(page=1, limit=limit)['search_total']\n",
    "pages = math.ceil(total_ads/limit)\n",
    "\n",
    "# Iterate through all pages in region=20 (Lausanne) and\n",
    "for page in np.arange(1, pages+1):\n",
    "    j = getTutti(page=page, limit=limit)\n",
    "    filename = DIR + 'page_' + str(page) + '.json'\n",
    "    saveJson(j, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point there are *pages* different JSON file that need to be read, merged and cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Open, merge and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all *json* in dir and save it on a JSON. \n",
    "\n",
    "The `json_normalize` function turned out to be very useful to flatten all JSON cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json_filename = os.listdir(DIR)\n",
    "# Take only .json file\n",
    "all_json_filename = list(filter(lambda x: x.endswith('.json'), all_json_filename))\n",
    "\n",
    "all_json = []\n",
    "\n",
    "for j_ in all_json_filename:\n",
    "    print(j_)\n",
    "    j_tmp = loadJson(DIR + j_)\n",
    "    \n",
    "    # Read JSON (and flatten values)\n",
    "    pd_ = json_normalize(j_tmp['items'])\n",
    "    \n",
    "    # Save pandas obj \n",
    "    all_json.append(pd_)\n",
    "    \n",
    "df = pd.concat(all_json, ignore_index=True ,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame df still contains a column 'parameters' that is not an easy parsable JSON object. Get rid of it in a dirty way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posIdInParameter(id_, p):\n",
    "    \"\"\"Return position of the list where the id is contained\"\"\"\n",
    "    pos = -1\n",
    "    values = [value['id'] for value in p]\n",
    "    zip_ = dict(zip(values, np.arange(0,len(p))))\n",
    "    if (id_ in values):\n",
    "        pos = zip_[id_]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanParameter(p):\n",
    "    \"\"\"From parameter objects p, return Pandas Series with only nmr. of rooms, size and type\"\"\"\n",
    "    \n",
    "    rooms, size, type_ = [np.nan] * 3\n",
    "    \n",
    "    # Check for rooms\n",
    "    pos_rooms = posIdInParameter('rooms', p)\n",
    "    if (pos_rooms != -1):\n",
    "        rooms = p[pos_rooms]['value']\n",
    "        \n",
    "    # Check for size\n",
    "    pos_size = posIdInParameter('size', p)\n",
    "    if (pos_size != -1):\n",
    "        size = p[pos_size]['value']\n",
    "        \n",
    "    # Check for type_\n",
    "    pos_type = posIdInParameter('type', p)\n",
    "    if (pos_type != -1):\n",
    "        type_ = p[pos_type]['value']\n",
    "    \n",
    "    return pd.Series([rooms, size, type_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = df['parameters'].apply(lambda p: cleanParameter(p))\n",
    "parameters.columns = ['rooms', 'size', 'type_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(parameters, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# Drop not useful columns\n",
    "not_useful_columns = ['company_ad', \n",
    "                      'image_names', \n",
    "                      'language', \n",
    "                      'parameters', \n",
    "                      'phone_hash', \n",
    "                      'thumb_name', \n",
    "                      'category_info.id',\n",
    "                      'category_info.parent_id',\n",
    "                      'category_info.parent_name',\n",
    "                      'highlight',\n",
    "                      'location_info.area', # since all 'lausanne',\n",
    "                      'location_info.area_id',\n",
    "                      'location_info.region_name',\n",
    "                      'location_info.region_id',\n",
    "                      'public_account_id',\n",
    "                     ]\n",
    "df.drop(not_useful_columns, axis='columns', inplace=True)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tutti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('tutti.csv')\n",
    "df2.shape\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data analysis ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df2['location_info.address'].isna())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
